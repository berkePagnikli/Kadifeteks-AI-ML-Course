"""
Ãœretim HattÄ±ndan Gelen Veri Setini Analiz Etme
(Production Line Dataset Analysis)

Bu proje NumPy ve Pandas kullanarak gerÃ§ek Ã¼retim verilerini analiz eder:
- Veri okuma ve temizleme
- Ä°statistiksel analiz
- Trend analizi  
- GÃ¶rselleÅŸtirme hazÄ±rlÄ±ÄŸÄ±
- Performans metrikleri

This project demonstrates advanced data analysis using NumPy and Pandas
for production line dataset analysis and insights generation.
"""

import numpy as np
import pandas as pd
import datetime
import random
from collections import defaultdict

print("=" * 70)
print("ÃœRETÄ°M HATTI VERÄ° ANALÄ°ZÄ° - NUMPY & PANDAS PROJESÄ°")
print("PRODUCTION LINE DATA ANALYSIS - NUMPY & PANDAS PROJECT")
print("=" * 70)

# =====================================
# PART 1: VERÄ° SETÄ° OLUÅTURMA
# =====================================
print("\n1. VERÄ° SETÄ° OLUÅTURMA (Dataset Creation)")
print("-" * 50)

def create_production_dataset(num_records=1000):
    """
    GerÃ§ekÃ§i Ã¼retim hattÄ± verisi oluÅŸturur
    """
    np.random.seed(42)  # Tekrarlanabilir sonuÃ§lar iÃ§in
    random.seed(42)
    
    # Tarih aralÄ±ÄŸÄ± oluÅŸtur (son 90 gÃ¼n)
    end_date = datetime.date.today()
    start_date = end_date - datetime.timedelta(days=90)
    date_range = pd.date_range(start=start_date, end=end_date, freq='D')
    
    data = []
    
    for i in range(num_records):
        # Rastgele tarih seÃ§
        production_date = random.choice(date_range)
        
        # Haftasonu etkisi (daha az Ã¼retim)
        is_weekend = production_date.weekday() >= 5
        base_efficiency = 0.7 if is_weekend else 0.9
        
        # Vardiya etkisi
        shift = random.choice(['GÃ¼ndÃ¼z', 'Gece', 'Hafta sonu'])
        shift_efficiency = {'GÃ¼ndÃ¼z': 1.0, 'Gece': 0.85, 'Hafta sonu': 0.75}
        
        # Makine performansÄ± (normale yakÄ±n daÄŸÄ±lÄ±m)
        machine_efficiency = np.random.normal(base_efficiency * shift_efficiency[shift], 0.1)
        machine_efficiency = np.clip(machine_efficiency, 0.3, 1.0)
        
        # Ãœretim metrikleri
        target_production = 100  # GÃ¼nlÃ¼k hedef
        actual_production = int(target_production * machine_efficiency + np.random.normal(0, 5))
        actual_production = max(0, actual_production)
        
        # Kalite metrikleri
        base_quality = 95
        quality_score = base_quality + np.random.normal(0, 3) - (5 if is_weekend else 0)
        quality_score = np.clip(quality_score, 70, 100)
        
        # Hata sayÄ±sÄ± (kalite ile ters orantÄ±lÄ±)
        defect_rate = np.random.poisson(max(0, (100 - quality_score) / 10))
        
        # Enerji tÃ¼ketimi
        energy_consumption = actual_production * np.random.uniform(1.8, 2.2) + np.random.normal(0, 5)
        energy_consumption = max(0, energy_consumption)
        
        # Makine durma sÃ¼resi
        downtime = np.random.exponential(2) if random.random() < 0.15 else 0
        downtime = min(downtime, 8)  # Maksimum 8 saat
        
        record = {
            'tarih': production_date,
            'vardiya': shift,
            'makine_id': f"M{random.randint(1, 10):02d}",
            'operatÃ¶r': random.choice(['Ali', 'AyÅŸe', 'Mehmet', 'Fatma', 'Can', 'Elif', 'Burak', 'Zeynep']),
            'hedef_Ã¼retim': target_production,
            'gerÃ§ek_Ã¼retim': actual_production,
            'kalite_skoru': round(quality_score, 2),
            'hata_sayÄ±sÄ±': defect_rate,
            'enerji_tÃ¼ketimi': round(energy_consumption, 2),
            'makine_durma_sÃ¼resi': round(downtime, 2),
            'Ã¼retim_hÄ±zÄ±': round(actual_production / max(1, 8 - downtime), 2),
            'verimlilik': round((actual_production / target_production) * 100, 2),
            'maliyet': round(energy_consumption * 0.15 + defect_rate * 50 + downtime * 200, 2)
        }
        
        data.append(record)
    
    return pd.DataFrame(data)

# Veri setini oluÅŸtur
df = create_production_dataset(1000)
print(f"OluÅŸturulan veri seti: {df.shape[0]} satÄ±r, {df.shape[1]} sÃ¼tun")
print("\nVeri seti ilk 5 satÄ±r:")
print(df.head())

print("\nVeri seti bilgileri:")
print(df.info())

# =====================================
# PART 2: VERÄ° KEÅFI VE TEMÄ°ZLEME
# =====================================
print("\n\n2. VERÄ° KEÅFÄ° VE TEMÄ°ZLEME (Data Exploration and Cleaning)")
print("-" * 50)

# Temel istatistikler
print("\n2.1 Temel Ä°statistikler:")
print(df.describe())

# Eksik veri kontrolÃ¼
print("\n2.2 Eksik Veri KontrolÃ¼:")
missing_data = df.isnull().sum()
print(missing_data[missing_data > 0])
if missing_data.sum() == 0:
    print("Eksik veri bulunamadÄ±! âœ“")

# AykÄ±rÄ± deÄŸer tespiti
print("\n2.3 AykÄ±rÄ± DeÄŸer Analizi:")
numerical_columns = ['gerÃ§ek_Ã¼retim', 'kalite_skoru', 'enerji_tÃ¼ketimi', 'verimlilik']

outliers_info = {}
for col in numerical_columns:
    Q1 = df[col].quantile(0.25)
    Q3 = df[col].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    
    outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]
    outliers_info[col] = len(outliers)
    
    print(f"{col}: {len(outliers)} aykÄ±rÄ± deÄŸer tespit edildi")

# Veri tipleri optimizasyonu
print("\n2.4 Veri Tipi Optimizasyonu:")
original_memory = df.memory_usage(deep=True).sum()
print(f"Orijinal hafÄ±za kullanÄ±mÄ±: {original_memory / 1024:.2f} KB")

# Tarihleri datetime'a Ã§evir
df['tarih'] = pd.to_datetime(df['tarih'])

# Kategorik verileri category tipine Ã§evir
categorical_columns = ['vardiya', 'makine_id', 'operatÃ¶r']
for col in categorical_columns:
    df[col] = df[col].astype('category')

optimized_memory = df.memory_usage(deep=True).sum()
print(f"Optimize edilmiÅŸ hafÄ±za kullanÄ±mÄ±: {optimized_memory / 1024:.2f} KB")
print(f"HafÄ±za tasarrufu: %{((original_memory - optimized_memory) / original_memory * 100):.1f}")

# =====================================
# PART 3: NUMPY Ä°LE Ä°LERÄ° ANALÄ°Z
# =====================================
print("\n\n3. NUMPY Ä°LE Ä°LERÄ° ANALÄ°Z (Advanced Analysis with NumPy)")
print("-" * 50)

# NumPy array'lerine dÃ¶nÃ¼ÅŸtÃ¼r
production_array = df['gerÃ§ek_Ã¼retim'].values
quality_array = df['kalite_skoru'].values
efficiency_array = df['verimlilik'].values
energy_array = df['enerji_tÃ¼ketimi'].values

print("\n3.1 Ãœretim PerformansÄ± Analizi:")
print(f"Ortalama Ã¼retim: {np.mean(production_array):.2f}")
print(f"Medyan Ã¼retim: {np.median(production_array):.2f}")
print(f"Standart sapma: {np.std(production_array):.2f}")
print(f"Minimum Ã¼retim: {np.min(production_array)}")
print(f"Maksimum Ã¼retim: {np.max(production_array)}")

# YÃ¼zdelik dilimler
percentiles = np.percentile(production_array, [25, 50, 75, 90, 95])
print(f"YÃ¼zdelik dilimler (25, 50, 75, 90, 95): {percentiles}")

print("\n3.2 Kalite-Ãœretim Korelasyonu:")
correlation = np.corrcoef(production_array, quality_array)[0, 1]
print(f"Ãœretim-Kalite korelasyonu: {correlation:.3f}")

# Kalite kategorileri
quality_categories = np.where(quality_array >= 95, 'YÃ¼ksek',
                             np.where(quality_array >= 85, 'Orta', 'DÃ¼ÅŸÃ¼k'))
unique_categories, counts = np.unique(quality_categories, return_counts=True)
print("\nKalite kategorisi daÄŸÄ±lÄ±mÄ±:")
for cat, count in zip(unique_categories, counts):
    print(f"  {cat}: {count} ({count/len(quality_array)*100:.1f}%)")

print("\n3.3 Verimlilik Analizi:")
high_efficiency = efficiency_array[efficiency_array >= 90]
low_efficiency = efficiency_array[efficiency_array < 70]

print(f"YÃ¼ksek verimlilik (â‰¥90%) gÃ¼n sayÄ±sÄ±: {len(high_efficiency)}")
print(f"DÃ¼ÅŸÃ¼k verimlilik (<70%) gÃ¼n sayÄ±sÄ±: {len(low_efficiency)}")
print(f"Ortalama yÃ¼ksek verimlilik gÃ¼nÃ¼ Ã¼retimi: {np.mean(production_array[efficiency_array >= 90]):.2f}")
print(f"Ortalama dÃ¼ÅŸÃ¼k verimlilik gÃ¼nÃ¼ Ã¼retimi: {np.mean(production_array[efficiency_array < 70]):.2f}")

# =====================================
# PART 4: PANDAS Ä°LE GROUPBY ANALÄ°ZÄ°
# =====================================
print("\n\n4. PANDAS Ä°LE GROUPBY ANALÄ°ZÄ° (GroupBy Analysis with Pandas)")
print("-" * 50)

print("\n4.1 Vardiya BazlÄ± Analiz:")
shift_analysis = df.groupby('vardiya').agg({
    'gerÃ§ek_Ã¼retim': ['mean', 'std', 'sum'],
    'kalite_skoru': ['mean', 'min', 'max'],
    'verimlilik': 'mean',
    'enerji_tÃ¼ketimi': 'mean',
    'hata_sayÄ±sÄ±': 'sum'
}).round(2)

print(shift_analysis)

print("\n4.2 Makine BazlÄ± Performans:")
machine_performance = df.groupby('makine_id').agg({
    'gerÃ§ek_Ã¼retim': 'sum',
    'kalite_skoru': 'mean',
    'makine_durma_sÃ¼resi': 'sum',
    'verimlilik': 'mean',
    'maliyet': 'sum'
}).round(2)

# En iyi ve en kÃ¶tÃ¼ makineler
best_machine = machine_performance.loc[machine_performance['verimlilik'].idxmax()]
worst_machine = machine_performance.loc[machine_performance['verimlilik'].idxmin()]

print(f"En verimli makine: {machine_performance['verimlilik'].idxmax()}")
print(f"  Verimlilik: {best_machine['verimlilik']:.2f}%")
print(f"  Toplam Ã¼retim: {best_machine['gerÃ§ek_Ã¼retim']}")
print(f"  Ortalama kalite: {best_machine['kalite_skoru']:.2f}")

print(f"\nEn az verimli makine: {machine_performance['verimlilik'].idxmin()}")
print(f"  Verimlilik: {worst_machine['verimlilik']:.2f}%")
print(f"  Toplam Ã¼retim: {worst_machine['gerÃ§ek_Ã¼retim']}")
print(f"  Ortalama kalite: {worst_machine['kalite_skoru']:.2f}")

print("\n4.3 OperatÃ¶r PerformansÄ±:")
operator_performance = df.groupby('operatÃ¶r').agg({
    'gerÃ§ek_Ã¼retim': ['mean', 'sum'],
    'kalite_skoru': 'mean',
    'verimlilik': 'mean',
    'hata_sayÄ±sÄ±': 'mean'
}).round(2)

# En iyi operatÃ¶rÃ¼ bul
operator_performance.columns = ['_'.join(col).strip() for col in operator_performance.columns]
top_operator = operator_performance.loc[operator_performance['verimlilik_mean'].idxmax()]

print(f"En verimli operatÃ¶r: {operator_performance['verimlilik_mean'].idxmax()}")
print(f"  Ortalama verimlilik: {top_operator['verimlilik_mean']:.2f}%")
print(f"  Ortalama kalite: {top_operator['kalite_skoru_mean']:.2f}")

# =====================================
# PART 5: ZAMAN SERÄ°SÄ° ANALÄ°ZÄ°
# =====================================
print("\n\n5. ZAMAN SERÄ°SÄ° ANALÄ°ZÄ° (Time Series Analysis)")
print("-" * 50)

# GÃ¼nlÃ¼k agregasyon
daily_data = df.groupby('tarih').agg({
    'gerÃ§ek_Ã¼retim': 'sum',
    'kalite_skoru': 'mean',
    'verimlilik': 'mean',
    'enerji_tÃ¼ketimi': 'sum',
    'maliyet': 'sum'
}).round(2)

print("\n5.1 GÃ¼nlÃ¼k Trend Analizi:")
print(f"Ä°lk gÃ¼nkÃ¼ toplam Ã¼retim: {daily_data['gerÃ§ek_Ã¼retim'].iloc[0]}")
print(f"Son gÃ¼nkÃ¼ toplam Ã¼retim: {daily_data['gerÃ§ek_Ã¼retim'].iloc[-1]}")

# 7 gÃ¼nlÃ¼k hareketli ortalama
daily_data['Ã¼retim_7gÃ¼n_ort'] = daily_data['gerÃ§ek_Ã¼retim'].rolling(window=7).mean()
daily_data['kalite_7gÃ¼n_ort'] = daily_data['kalite_skoru'].rolling(window=7).mean()

print(f"Son 7 gÃ¼nÃ¼n ortalama Ã¼retimi: {daily_data['Ã¼retim_7gÃ¼n_ort'].iloc[-1]:.2f}")
print(f"Son 7 gÃ¼nÃ¼n ortalama kalitesi: {daily_data['kalite_7gÃ¼n_ort'].iloc[-1]:.2f}")

# Hafta iÃ§i vs hafta sonu
df['gÃ¼n_tipi'] = df['tarih'].dt.weekday.apply(lambda x: 'Hafta_sonu' if x >= 5 else 'Hafta_iÃ§i')
day_type_analysis = df.groupby('gÃ¼n_tipi').agg({
    'gerÃ§ek_Ã¼retim': 'mean',
    'kalite_skoru': 'mean',
    'verimlilik': 'mean'
}).round(2)

print("\n5.2 Hafta Ä°Ã§i vs Hafta Sonu:")
print(day_type_analysis)

# =====================================
# PART 6: PERFORMANS METRÄ°KLERÄ°
# =====================================
print("\n\n6. PERFORMANS METRÄ°KLERÄ° (Performance Metrics)")
print("-" * 50)

print("\n6.1 Genel Performans KPI'larÄ±:")

# OEE (Overall Equipment Effectiveness) hesaplama
df['availability'] = (480 - df['makine_durma_sÃ¼resi'] * 60) / 480  # 8 saatlik vardiya
df['performance'] = df['gerÃ§ek_Ã¼retim'] / df['hedef_Ã¼retim']
df['quality_rate'] = (df['gerÃ§ek_Ã¼retim'] - df['hata_sayÄ±sÄ±']) / df['gerÃ§ek_Ã¼retim']
df['quality_rate'] = df['quality_rate'].fillna(0).clip(0, 1)
df['oee'] = df['availability'] * df['performance'] * df['quality_rate']

average_oee = df['oee'].mean() * 100
print(f"Ortalama OEE (Overall Equipment Effectiveness): {average_oee:.2f}%")

# DÃ¼nya standartlarÄ± ile karÅŸÄ±laÅŸtÄ±rma
if average_oee >= 85:
    oee_status = "DÃ¼nya standartlarÄ± (MÃ¼kemmel)"
elif average_oee >= 65:
    oee_status = "Kabul edilebilir"
else:
    oee_status = "GeliÅŸtirilmeli"

print(f"OEE DeÄŸerlendirmesi: {oee_status}")

# DiÄŸer KPI'lar
print(f"Ortalama Kalite Skoru: {df['kalite_skoru'].mean():.2f}")
print(f"Ortalama Verimlilik: {df['verimlilik'].mean():.2f}%")
print(f"Toplam Ãœretim: {df['gerÃ§ek_Ã¼retim'].sum():,} birim")
print(f"Toplam Hata: {df['hata_sayÄ±sÄ±'].sum()} birim")
print(f"Hata OranÄ±: {(df['hata_sayÄ±sÄ±'].sum() / df['gerÃ§ek_Ã¼retim'].sum() * 100):.3f}%")

print("\n6.2 Maliyet Analizi:")
total_cost = df['maliyet'].sum()
cost_per_unit = total_cost / df['gerÃ§ek_Ã¼retim'].sum()
print(f"Toplam Maliyet: {total_cost:,.2f} TL")
print(f"Birim Maliyet: {cost_per_unit:.2f} TL/birim")

# Maliyet daÄŸÄ±lÄ±mÄ±
energy_cost = (df['enerji_tÃ¼ketimi'] * 0.15).sum()
defect_cost = (df['hata_sayÄ±sÄ±'] * 50).sum()
downtime_cost = (df['makine_durma_sÃ¼resi'] * 200).sum()

print(f"Enerji Maliyeti: {energy_cost:,.2f} TL ({energy_cost/total_cost*100:.1f}%)")
print(f"Hata Maliyeti: {defect_cost:,.2f} TL ({defect_cost/total_cost*100:.1f}%)")
print(f"Durma Maliyeti: {downtime_cost:,.2f} TL ({downtime_cost/total_cost*100:.1f}%)")

# =====================================
# PART 7: NUMPY Ä°LE Ä°STATÄ°STÄ°KSEL TESTLER
# =====================================
print("\n\n7. Ä°STATÄ°STÄ°KSEL ANALÄ°Z (Statistical Analysis)")
print("-" * 50)

print("\n7.1 Vardiya Performans KarÅŸÄ±laÅŸtÄ±rmasÄ±:")

# Vardiyalar arasÄ± Ã¼retim farkÄ±
day_shift = df[df['vardiya'] == 'GÃ¼ndÃ¼z']['gerÃ§ek_Ã¼retim'].values
night_shift = df[df['vardiya'] == 'Gece']['gerÃ§ek_Ã¼retim'].values

print(f"GÃ¼ndÃ¼z vardiyasÄ± ortalama Ã¼retim: {np.mean(day_shift):.2f}")
print(f"Gece vardiyasÄ± ortalama Ã¼retim: {np.mean(night_shift):.2f}")
print(f"Fark: {np.mean(day_shift) - np.mean(night_shift):.2f} birim")

# GÃ¼ven aralÄ±ÄŸÄ± hesaplama
def confidence_interval(data, confidence=0.95):
    mean = np.mean(data)
    std_err = np.std(data) / np.sqrt(len(data))
    margin = 1.96 * std_err  # %95 gÃ¼ven aralÄ±ÄŸÄ± iÃ§in
    return mean - margin, mean + margin

day_ci = confidence_interval(day_shift)
night_ci = confidence_interval(night_shift)

print(f"GÃ¼ndÃ¼z vardiyasÄ± %95 gÃ¼ven aralÄ±ÄŸÄ±: [{day_ci[0]:.2f}, {day_ci[1]:.2f}]")
print(f"Gece vardiyasÄ± %95 gÃ¼ven aralÄ±ÄŸÄ±: [{night_ci[0]:.2f}, {night_ci[1]:.2f}]")

print("\n7.2 Kalite KontrolÃ¼ Ä°statistikleri:")
# Kontrol limitleri (3-sigma)
quality_mean = np.mean(quality_array)
quality_std = np.std(quality_array)
ucl = quality_mean + 3 * quality_std  # Upper Control Limit
lcl = quality_mean - 3 * quality_std  # Lower Control Limit

print(f"Kalite ortalamasÄ±: {quality_mean:.2f}")
print(f"Ãœst kontrol limiti (UCL): {ucl:.2f}")
print(f"Alt kontrol limiti (LCL): {lcl:.2f}")

# Kontrol dÄ±ÅŸÄ± noktalar
out_of_control = np.sum((quality_array > ucl) | (quality_array < lcl))
print(f"Kontrol dÄ±ÅŸÄ± nokta sayÄ±sÄ±: {out_of_control} ({out_of_control/len(quality_array)*100:.2f}%)")

# =====================================
# PART 8: GELECEK TAHMÄ°NÄ°
# =====================================
print("\n\n8. GELECEK TAHMÄ°NÄ° (Future Predictions)")
print("-" * 50)

print("\n8.1 Basit Trend Tahmini:")
# Son 30 gÃ¼nÃ¼n verisi ile lineer trend
recent_data = daily_data.tail(30).reset_index()
recent_data['gÃ¼n_sayÄ±sÄ±'] = range(len(recent_data))

# Numpy ile lineer regresyon
X = recent_data['gÃ¼n_sayÄ±sÄ±'].values
y = recent_data['gerÃ§ek_Ã¼retim'].values

# y = mx + b formatÄ±nda
n = len(X)
sum_x = np.sum(X)
sum_y = np.sum(y)
sum_xy = np.sum(X * y)
sum_x2 = np.sum(X ** 2)

# Slope (eÄŸim) ve intercept (kesim) hesaplama
slope = (n * sum_xy - sum_x * sum_y) / (n * sum_x2 - sum_x ** 2)
intercept = (sum_y - slope * sum_x) / n

print(f"Trend eÄŸimi: {slope:.2f} birim/gÃ¼n")
if slope > 0:
    print("Ãœretim artÄ±ÅŸ trendinde âœ“")
else:
    print("Ãœretim azalÄ±ÅŸ trendinde âš ")

# Gelecek 7 gÃ¼nÃ¼n tahmini
future_days = 7
future_predictions = []
for i in range(1, future_days + 1):
    prediction = slope * (len(recent_data) + i) + intercept
    future_predictions.append(prediction)

print(f"\nGelecek {future_days} gÃ¼nÃ¼n tahmini Ã¼retimi:")
for i, pred in enumerate(future_predictions, 1):
    print(f"  GÃ¼n {i}: {pred:.0f} birim")

total_predicted = sum(future_predictions)
print(f"Toplam tahmini haftalÄ±k Ã¼retim: {total_predicted:.0f} birim")

# =====================================
# PART 9: ACTIONABLE INSIGHTS
# =====================================
print("\n\n9. EYLEMSEL Ã–NGÃ–RÃœLER (Actionable Insights)")
print("-" * 50)

def generate_insights(df):
    insights = []
    
    # Verimlilik analizi
    low_efficiency_threshold = df['verimlilik'].quantile(0.25)
    low_efficiency_count = (df['verimlilik'] < low_efficiency_threshold).sum()
    if low_efficiency_count > len(df) * 0.3:
        insights.append(f"âš  DÃ¼ÅŸÃ¼k verimlilik problemi: {low_efficiency_count} kayÄ±t (%{low_efficiency_count/len(df)*100:.1f})")
    
    # Makine durma sÃ¼releri
    high_downtime = df[df['makine_durma_sÃ¼resi'] > 2]
    if len(high_downtime) > 0:
        worst_machines = high_downtime.groupby('makine_id')['makine_durma_sÃ¼resi'].sum().nlargest(3)
        insights.append(f"ğŸ”§ En fazla duran makineler: {', '.join(worst_machines.index.tolist())}")
    
    # Kalite sorunlarÄ±
    low_quality_count = (df['kalite_skoru'] < 85).sum()
    if low_quality_count > 0:
        insights.append(f"ğŸ“‰ DÃ¼ÅŸÃ¼k kalite uyarÄ±sÄ±: {low_quality_count} kayÄ±t kalite standardÄ±nÄ±n altÄ±nda")
    
    # Enerji verimliliÄŸi
    high_energy_per_unit = df['enerji_tÃ¼ketimi'] / df['gerÃ§ek_Ã¼retim']
    inefficient_energy = (high_energy_per_unit > high_energy_per_unit.quantile(0.8)).sum()
    if inefficient_energy > 0:
        insights.append(f"âš¡ Enerji verimliliÄŸi uyarÄ±sÄ±: {inefficient_energy} kayÄ±t yÃ¼ksek enerji tÃ¼ketimi")
    
    # OperatÃ¶r performansÄ±
    operator_variance = df.groupby('operatÃ¶r')['verimlilik'].std()
    inconsistent_operators = operator_variance[operator_variance > 15].index.tolist()
    if inconsistent_operators:
        insights.append(f"ğŸ‘¥ TutarsÄ±z performans: {', '.join(inconsistent_operators)} operatÃ¶rleri")
    
    return insights

insights = generate_insights(df)
print("Tespit Edilen Ana Sorunlar:")
for insight in insights:
    print(f"  {insight}")

print("\n9.2 Ã–nerilen Eylemler:")
recommendations = [
    "1. DÃ¼ÅŸÃ¼k verimli makinelerde bakÄ±m planÄ± uygulayÄ±n",
    "2. En iyi performanslÄ± operatÃ¶rlerin deneyimlerini paylaÅŸtÄ±rÄ±n", 
    "3. Gece vardiyasÄ± iÃ§in ek kalite kontrol Ã¶nlemleri alÄ±n",
    "4. Enerji tÃ¼ketimi yÃ¼ksek olan sÃ¼reÃ§leri optimize edin",
    "5. Makine duruÅŸ sÃ¼relerini azaltmak iÃ§in preventif bakÄ±m planÄ± yapÄ±n"
]

for rec in recommendations:
    print(f"  {rec}")

# =====================================
# PART 10: RAPOR Ã–ZET
# =====================================
print("\n\n10. RAPOR Ã–ZETÄ° (Report Summary)")
print("-" * 50)

print(f"""
ÃœRETIM HATTI PERFORMANS RAPORU
===============================

VERÄ° SETÄ° BÄ°LGÄ°LERÄ°:
â€¢ Analiz edilen kayÄ±t sayÄ±sÄ±: {len(df):,}
â€¢ Tarih aralÄ±ÄŸÄ±: {df['tarih'].min().strftime('%d.%m.%Y')} - {df['tarih'].max().strftime('%d.%m.%Y')}
â€¢ Toplam makine sayÄ±sÄ±: {df['makine_id'].nunique()}
â€¢ Toplam operatÃ¶r sayÄ±sÄ±: {df['operatÃ¶r'].nunique()}

ANA PERFORMANS GÃ–STERGELERÄ°:
â€¢ Ortalama OEE: %{average_oee:.1f} ({oee_status})
â€¢ Toplam Ã¼retim: {df['gerÃ§ek_Ã¼retim'].sum():,} birim
â€¢ Ortalama kalite skoru: {df['kalite_skoru'].mean():.1f}/100
â€¢ Ortalama verimlilik: %{df['verimlilik'].mean():.1f}
â€¢ Toplam maliyet: {total_cost:,.0f} TL
â€¢ Birim maliyet: {cost_per_unit:.2f} TL

TREND ANALÄ°ZÄ°:
â€¢ GÃ¼nlÃ¼k Ã¼retim trendi: {slope:.1f} birim/gÃ¼n {'(Artan)' if slope > 0 else '(Azalan)'}
â€¢ Gelecek hafta tahmini: {total_predicted:.0f} birim

KRÄ°TÄ°K BULGULAR:
{chr(10).join([f'â€¢ {insight}' for insight in insights]) if insights else 'â€¢ Kritik sorun tespit edilmedi âœ“'}

Bu analiz NumPy ve Pandas kullanÄ±larak gerÃ§ekleÅŸtirilmiÅŸtir.
KullanÄ±lan teknikler:
- Veri keÅŸfi ve temizleme
- Ä°statistiksel analiz ve korelasyon
- Zaman serisi analizi
- Performans metrikleri (OEE)
- Trend analizi ve tahmin
- Actionable insights Ã¼retimi
""")

print("\n" + "=" * 70)
print("VERÄ° ANALÄ°ZÄ° TAMAMLANDI - ANALYSIS COMPLETED")
print("=" * 70)